Introduction to UNIX & POSIX
Master 1

Sebastien Binet
CNRS/IN2P3/LPC-Clermont
sebastien.binet@clermont.in2p3.fr

* UNIX

* UNIX

From [[https://en.wikipedia.org/wiki/Unix][Wikipedia]]:

 UNIX is a family of multitasking, multiuser computer operating systems
 that derive from the original AT&T Unix, development starting in the
 1970s at Bell Labs research center by Ken Thompson, Dennis Ritchie,
 Douglas McIlroy and Joe Ossanna.

An operating system (OS) is the suite of programs that make a computer work.

UNIX is a stable OS, used for servers, desktops, laptops, tablets and smartphones.

UNIX systems also expose a graphical user interface (*GUI*) not unlike Microsoft Windows (TM).

But for scientific work, the command-line interface that UNIX provides (a.k.a the *shell*) is a real productivity boon.

* UNIX: Linux, FreeBSD, Darwin, ...

There are many different versions of UNIX.

But they all share a common lineage and similarities.
The most popular varieties of UNIX are:

- Linux (CentOS, Debian, Ubuntu, ...)
- macOS
- BSDs (FreeBSD, NetBSD, OpenBSD, ...)
- Solaris

* 

.image _figs/unix-history.svg 600 _

* UNIX Operating System: 3 parts

- the *kernel* -- the heart of the OS: it bridges the applications and the hardware (CPU, disk, printers, memory, screen, ...) it is running on, it allocates time and memory to programs, handles the filesystem and communications,
- the *shell* -- the interface between the user and the kernel: it's a command line interpreter (*CLI*),
- the *programs* that help administrate UNIX (creating files, users, directories, etc...)

.image _figs/unix-architecture.jpg 310 _

* UNIX - Introducing the shell

At a high level, computers can do 4 things:

- run programs,
- store data,
- communicate with each others, and
- interact with us.

The shell allows to easily interact with the OS, run commands, script commands and, thus, automatize work.
The heart of a CLI is a *read-evaluate-print*loop* (*REPL* for short).

When the user types a command and the presses the `Enter` (or `Return`) key, the computer reads it, executes it and prints its output.
The user then types another command, and so on until the user logs off.

* UNIX - shell

The shell is a program, like any other.

Its job is to run other programs rather than do calculations itself.

Popular UNIX shells:

- [[https://en.wikipedia.org/wiki/Bash_(Unix_shell)][bash]]
- [[https://en.wikipedia.org/wiki/Tcsh][tcsh]]
- [[https://en.wikipedia.org/wiki/Z_shell][zsh]]

Why bother with a shell?

Commands are terse, with only a few keystrokes (and command completion), one can easily combine existing tools and programs into powerful pipelines, handle large volumes of data automatically.

Automation not only improves *productivity* but also *reproducibility* (that is paramount in any scientific activity.)

* Example - a pipeline

Nelle Nemo, a marine biologist, has just returned from a six-month survey of the [[https://en.wikipedia.org/wiki/North_Pacific_Gyre][North Pacific Gyre]], where she has been sampling gelatinous marine life in the [[https://en.wikipedia.org/wiki/Great_Pacific_Garbage_Patch][Great Pacific Garbage Patch]]. She has 1520 samples in all and now needs to:

- Run each sample through an assay machine that will measure the relative abundance of 300 different proteins. The machine’s output for a single sample is a file with one line for each protein.
- Calculate statistics for each of the proteins separately using a program her supervisor wrote called `goostats`.
- Compare the statistics for each protein with corresponding statistics for each other protein using a program one of the other graduate students wrote called `goodiff`.
- Write up results. Her supervisor would really like her to do this by the end of the month so that her paper can appear in an upcoming special issue of Aquatic Goo Letters.

* Example - a pipeline

It takes about half an hour for the assay machine to process each sample.
The good news is that it only takes two minutes to set each one up.
Since her lab has eight assay machines that she can use in parallel, this step will “only” take about two weeks.

The bad news is that if she has to run `goostats` and `goodiff` by hand, she’ll have to enter filenames and click `“OK”` 46,370 times (1520 runs of `goostats`, plus 300*299/2 (half of 300 times 299) runs of `goodiff`).
At 30 seconds each, that will take more than two weeks.
Not only would she miss her paper deadline, the chances of her typing all of those commands right are practically zero.

In the following, we'll see how to leverage the command shell to automate the repetitive steps.

* Shell - a summary

- a shell is a program whose primary purpose is to read commands and run other programs,
- the shell's main advantages are its high _action-to-keystroke_ ration, its support for automation of repetitive tasks, and its capacity to access network machines
- the shell's main disadvantages are its primarily textual nature and how cryptic its commands and operation can be (at first.)

* Navigating files and directories

* Introduction to the filesystem

The part of the OS responsible for managing files and directories is called the *file* *system*.

It organizes our data into:

- files, which hold information, and
- directories (also called "folders"), which hold files or other directories.

Several commands are frequently used to create, inspect, rename and delete files and directories.

To start exploring them, let's open a shell window.

* 

In the following, the shell's *prompt* will be represented as:

  $>

a _dollar_ sign followed by the _greater-than_ sign.

The *prompt* is the shell telling us it's waiting for input.

Type the command `whoami`, then press the `Enter` (or `Return`) key to send the command to the shell.

The command's output is the ID of the current user: it shows us who the shell things we are:

 $> whoami
 binet

* 

More specifically, when we type `whoami`, the shell:

- finds a program called `whoami`,
- runs that program,
- displays that program's output, then
- displays a new prompt to tell us that it's ready for more commands.

* 

The shell is a program that runs other programs rather than doing calculations itself.
So the commands you type must be the names of existing programs.

If you type the name of a program that does not exist and hit `Enter`, you will see an error message similar to this:

 $> my-command
 bash: my-command: command not found

The shell (here, `bash`) tells us that it could not find the program `"my-command"` because that program does not exist on this computer.

* pwd

Let's find out where we are by running a command `"pwd"` (which stands for _"print_ _working_ _directory"_).
At any moment, our *current* *working* *directory* is our current default directory, _i.e._ the directory that the computer assumes we want to run commands in, unless we explicitly specify something else.

Here, the computer's response is `/home/binet`, which is the *home* *directory*:

 $> pwd
 /home/binet

_Note:_ depending on whether you are on `Linux` or on `macOS`, the default home directory may differ. On `Linux`, it's `"/home/xxx"`, while on `macOS` it's usually `"/Users/xxx"`.

* 

To understand what a "home directory" is, let's have a look at how the file system as a whole is organized. For the sake of this example, we'll be illustrating the filesystem on our scientist Nelle's computer.

On Nelle's computer, the filesystem looks like this:

.image _figs/unix-filesystem.svg 150 _

At the top is the *root* *directory*, that holds everything else.
We refer to it using a slash character `/` on its own.
This is the leading slash in `"/Users/nelle"` or in `"/home/binet"`.

Inside that directory are several other directories: `bin`, `data`, `Users`, `tmp`, and so on.

# We know that our current working directory `/Users/nelle` is stored inside `/Users` because `/Users` is the first part of its name. Similarly, we know that `/Users` is stored inside the root directory `/` because its name begins with `/`.

* 

Underneath `/Users`, we find one directory for each user with an account on Nelle's machine:

.image _figs/unix-home-directories.svg 200 _

Typically, when you open a new command prompt, you will be in your home directory to start.

Now, let's learn the command that will let us see the contents of our own filesystem...

* ls

We can see what's in our home directory by running `ls`, which stands for _"listing"_:

 $> ls
 Applications Documents    Library      Music        Public
 Desktop      Downloads    Movies       Pictures

`ls` prints the names of the files and directories in the current directory in alphabetical order, arranged neatly into columns.

We can make its output more comprehensible by using the *flag* `-F`, which tells `ls` to add a trailing `/` to the names of directories:

 $> ls -F
 Applications/ Documents/    Library/      Music/        Public/
 Desktop/      Downloads/    Movies/       Pictures/

* ls

`ls` has lots and lots of other options. To find out what they are, we can type:

 $> ls --help
 Usage: ls [OPTION]... [FILE]...
 List information about the FILEs (the current directory by default).
 Sort entries alphabetically if none of -cftuvSUX nor --sort is specified.
 
 Mandatory arguments to long options are mandatory for short options too.
   -a, --all                  do not ignore entries starting with .
   -A, --almost-all           do not list implied . and ..
       --author               with -l, print the author of each file
   -b, --escape               print C-style escapes for nongraphic characters
       --block-size=SIZE      scale sizes by SIZE before printing them; e.g.,
                                '--block-size=M' prints sizes in units of
                                1,048,576 bytes; see SIZE format below
 [...]

Many `bash` commands and programs that people have written, support a `--help` flag to display more informations on how to use the commands or programs.

* man

For more informations on how to use `ls`, we can type `man` `ls`:

 $> man ls

`man` is the UNIX "manual" command: it prints a description of a command and its options, and sometimes, a few examples of how to use it.

To navigate through the `man` pages, you may use the up and down arrow keys to move line-by-line, or try the `"b"` and spacebar keys to skip up and down by full page.

Quit the `man` pages by typing `"q"`.

* 

We can also use `ls` to see the contents of a different directory.
Let's take a look at our `Downloads` directory by running:

 $> ls -F Downloads
 data-shell/

_i.e._: the command `ls` with the arguments `-F` and `Downloads`.
The second argument, the one _without_ a leading dash, tells `ls` that we want a listing of something other than our current working directory.

Now that we know the `data-shell` directory exists, we can do 2 things.

First, we can look at its contents, using the same strategy as before, passing a directory name to `ls`:

 $> ls -F Downloads/data-shell
 creatures/          molecules/          notes.txt           solar.pdf
 data/               north-pacific-gyre/ pizza.cfg           writing/ 

* cd

Second, we can actually change our location to a different directory, so we are no longer located in our home directory.

The command to change locations is `cd`, followed by a directory name to change our working directory. `cd` stands for "change directory".

To get to the `"data"` directory seen previously, we can use the following series of commands:

 $> cd Downloads
 $> cd data-shell
 $> cd data

To check we've indeed changed our current working directory, we can use `pwd`:

 $> pwd
 /Users/nelle/Downloads/data-shell/data
 $> ls -F
 amino-acids.txt   elements/     pdb/	        salmon.txt
 animals.txt       morse.txt     planets.txt    sunspot.txt

* 

We know how to go down the directory tree, but how to go up?
With `..`, the special directory that means "the directory containing this one":

 $> cd ..
 $> pwd
 /Users/nelle/Downloads/data-shell

Running `cd` without any argument brings you back to your home:

 $> cd
 $> pwd
 /Users/nelle

We can also give `cd` an argument that points to a very deep directory, instead of what we did last time:

 $> cd Downloads/data-shell/data
 $> pwd
 /Users/nelle/Downloads/data-shell/data

* Pop quizz

Starting from `/home/amanda/data/`, which of the following commands could Amanda use to navigate back to her home directory, `/home/amanda` ?

1. `cd` `.`
2. `cd` `/`
3. `cd` `/Users/amanda`
4. `cd` `../..`
5. `cd` `~`
6. `cd` `home`
7. `cd` `~/data/..`
8. `cd`
9. `cd` `..`

* Pop quizz - II

Using the filesystem diagram below, if `pwd` displays `/Users/thing`, what will the following command display ?

 $> ls ../backup

.image _figs/filesystem-challenge.svg 250 _

 1. ../backup: No such file or directory
 2. 2012-12-01 2013-01-08 2013-01-27
 3. 2012-12-01/ 2013-01-08/ 2013-01-27/
 4. original pnas_final pnas_sub

* Summary

- The filesystem is responsible for managing information on the disk
- information is stored in files, which are stored in directories (_a.k.a._ folders)
- directories can also store other directories, which forms a directory tree
- `cd` `path` changes the current working directory
- `ls` `path` prints a listing of a specific file or directory
- `..` means "the directory above the current one"
- `.` means "the current directory"
- most commands take options (flags) which begin with a dash `-`

* Working with files and directories

* 

We know how to explore files and directories, but how do we create them in the first place?

Let's go back to our `data-shell` directory and use `"ls` `-F"` to see what it contains:

 $> pwd
 /Users/nelle/Downloads/data-shell

 $> ls -F
 creatures/  molecules/           pizza.cfg
 data/       north-pacific-gyre/  solar.pdf

* 

Let's create a new directory called `thesis`, using the command `mkdir` (which has no output):

 $> mkdir thesis

`mkdir` means "make directory".
Since `thesis` is a relative path (_ie_ it doesn't have a leading slash), the new directory is created in the current working directory:

 $> ls -F
 creatures/  molecules/           pizza.cfg  thesis/
 data/       north-pacific-gyre/  solar.pdf

* Good names for files and directories

Complicated names of files and directories can make your life painful when working on the command line.
So, a few tips:

- don't use whitespaces. (use `-` or `_` instead)
- don't prefix names with `-` (dash): commands treat names starting with `-` as options,
- stick with letters, numbers, `.` (period), `-` (dash) and `_` (underscore). Many other characters have special meanings on the command line.

If you need to refer to names of files or directories that have whitespace or other non-alphanumeric characters, you should surround the name in quotes (`""`).

* 

Since we've just created the `thesis` directory, there's nothing in there yet:

 $> ls -F thesis

Let's go to `thesis` using `cd` and then run a text editor called `nano` to create a file called `draft.txt`:

 $> cd thesis
 $> nano draft.txt

Once we're happy with our text, we can press `Ctrl-O` to write our data to disk:

.image _figs/nano-screenshot.png 200 _

Once our file is saved, we can use `Ctrl-X` to quit the editor and return to the shell.

* 

After having exited `nano`, we should see a new `draft.txt` file:

 $> ls
 draft.txt

Let's tidy up by running:

 $> rm draft.txt

This command removes files (`rm` is short for "remove".)
If we run `ls` again, the output is empty once more, which tells us that our file is gone.


*WARNING:* The UNIX shell doesn't have a trash bin that we can recover deleted files from. *DELETING* *IS* *FOREVER*.

* 

Let's recreate that file and then move up one directory to `/Users/nelle/Downloads/data-shell` using `cd` `..`:

 $> pwd
 /Users/nelle/Downloads/data-shell/thesis
 $> nano draft.txt
 $> ls
 draft.txt
 $> cd ..

If we try to remove the entire `thesis` directory using `rm` `thesis`, we get:

 $> rm thesis
 rm: cannot remove `thesis': Is a directory

This happens because `rm` by default only works on files, not directories.
To really get rid of `thesis` we must also delete the file `draft.txt`.
We can do this with the recursive option for `rm`:

 $> rm -r thesis

* mv

Let's create that directory and file one more time:

 $> pwd
 /Users/nelle/Downloads/data-shell
 
 $> mkdir thesis
 $> nano thesis/draft.txt
 $> ls
 draft.txt

`draft.txt` isn't a particularly informative name: let's change the file's name using `mv` (short for "move"):

 $> mv thesis/draft.txt thesis/quotes.txt

The first parameter tells `mv` what we are moving, while the second is where it has to go.

* cp

The `cp` command works very much like `mv`, except it copies a file instead of moving it:

 $> cp thesis/quotes.txt ./quotations.txt
 $> ls quotations.txt thesis/quotes.txt
 quotations.txt thesis/quotes.txt


* Summary

- `cp` `old` `new` copies a file
- `mkdir` `path` creates a new directory
- `mv` `old` `new` moves (renames) a file or directory
- `rm` `path` removes (deletes) a file
- the shell does not have a trash bin: once something is deleted, it's really gone
- depending on the type of work you do, you may need a more powerful text editor than `nano`

* Pipes and filters

* 

Now that we know a few basic commands, we can finally look at the shells' most powerful features: the ease with which it lets us combine existing programs in new ways.
We'll start with a directory called `molecules` that contains six files describing some simple organic molecules.
The `.pdb` extension indicates that these are in Proteing Data Bank format, a simple text format that specifies the type and position of each atom in the molecule.

 $> ls molecules
 cubane.pdb  ethane.pdb  methane.pdb  octane.pdb  pentane.pdb  propane.pdb

* 

First, we need to download all of this data.
This can be done from, either:

.link https://github.com/master-pfa-info/2017/blob/master/testdata/shell-novice-data.zip
.link https://cern.ch/binet/master-pfa-info/2017/shell-novice-data.zip

Save it somewhere (probably insider a directory under `$HOME/M_username/` so it won't be automatically removed by the UCA bots)
and then:

 $> unzip shell-novice-data.zip
 $> ls data-shell/molecules
 cubane.pdb  ethane.pdb  methane.pdb  octane.pdb  pentane.pdb  propane.pdb

* 

Let's go into that directory with `cd` and run the command:

 $> cd data-shell/molecules
 $> wc *.pdb
  20  156 1158 cubane.pdb
  12   84  622 ethane.pdb
   9   57  422 methane.pdb
  30  246 1828 octane.pdb
  21  165 1226 pentane.pdb
  15  111  825 propane.pdb
 107  819 6081 total

`wc` is the "word count" command: it counts the number of lines, words and characters in files.
The `*` in `*.pdb` matches zero or more characters, so the shell turns `*.pdb` into a list of all `.pdb` files in the current directory.

* 

If we run:

 $> wc -l *.pdb
  20  cubane.pdb
  12  ethane.pdb
   9  methane.pdb
  30  octane.pdb
  21  pentane.pdb
  15  propane.pdb
 107  total

the output shows only the number of lines per file.

We can also use `-w` to get only the number of words or `-c` to get only the number of characters.

Which of these files is the shortest?
It's an easy question to answer when there are only six files, but what if there were 6000?

* 

Our first step toward a solution is to run the command:

 $> wc -l *.pdb > lengths.txt

The greater-than symbol (`>`) tells the shell to *redirect* the command's output to a file instead of printing it to the screen.

We can now send the content of `lengths.txt` to the screen using:

 $> cat lengths.txt
  20  cubane.pdb
  12  ethane.pdb
   9  methane.pdb
  30  octane.pdb
  21  pentane.pdb
  15  propane.pdb
 107  total

`cat` stands for "concatenate": it prints the contents of files one after another.

* 

Now let's use the `sort` command to sort its contents.
We will also use the `-n` flag to specify that the sort is numerical instead of alphabetical.
This does not change the file, instead it sends the sorted result to the screen:

 $> sort -n lengths.txt
   9  methane.pdb
  12  ethane.pdb
  15  propane.pdb
  20  cubane.pdb
  21  pentane.pdb
  30  octane.pdb
 107  total

We can put the sorted list of lines in another temporary file called `sorted-lengths.txt`:

 $> sort -n lengths.txt > sorted-lengths.txt
 $> head -n 1 sorted-lengths.txt
   9  methane.pdb

`head` prints the first few lines of a given file (`-n` `1` prints only one line).

* 

Having to deal with all these temporary files is a bit confusing.
We can make it easier to understand by running `sort` and `head` together:

 $> sort -n lengths.txt | head -n 1
   9  methane.pdb

The vertical bar `|` between the two commands is called a *pipe*.
It tells the shell that we want to use the output of the command on the left as the *input* to the command on the right.

The computer might create a temporary file if it needs to, or copy data from one program to the other in memory, or something else entirely: we don't have to know nor care.

* 

Nothing prevents us from chaining pipes consecutively:

 $> wc -l *.pdb | sort -n | head -n 1
   9  methane.pdb

This is exactly like a mathematician nesting functions like _log(3x)_ and saying "the log of three times x".
In our case, the calculation is "head of sort of line count of *.pdb".

* stdin, stdout & stderr

Here's what actually happens behind the scenes when we create a pipe.

When a computer runs a program -- any program -- it creates a *process* in memory to hold the program's software and its current state.

- every process has an input channel called *standard* *input* (_a.k.a._ `stdin`),
- every process has a default output channel called *standard* *output* (`stdout`),
- and a third output channel called *standard* *error* (`stderr`).

`stderr` is typically used for error or diagnostic messages and it allows a user to pipe the output of one program into another while still receiving error messages in the terminal.

* 

The shell is actually just another program.

Under normal circumstances, whatever we type on the keyboard is sent to the shell on its `stdin`, and whatever it produces on `stdout` is displayed on our screen.

When we tell the shell to run a program, it creates a new process and temporarily sends whatever we type on our keyboard to that process' `stdin` and whatever that process sends to its `stdout` appears on the screen.

* 

.image _figs/redirects-and-pipes.png 600 _

* 

This simple idea is why UNIX has been so successful.

Instead of creating enormous programs that try to do many different things, UNIX programmers focus on creating lots of simple tools that each do one job well, and that work well with each other.

This programming model is called "pipes and filters".

We've seen pipes; a *filter* is a program like `wc` or `sort` that transforms a stream of input into a stream of output.
Almost all of the standard UNIX tools can work that way: unless told to do otherwise, they read from standard input, do something with what they've read and write to standard output.

The key is that any program that reads lines of text from standard input and writes lines of text to standard output can be combined with every other program that behaves this way as well.
You can and _should_ write your programs this way so that you and other people can put those programs into pipes to multiply their power.


* Summary

- `cat` displays the content of its input(s)
- `head` displays the first few lines of its input
- `tail` displays the last few lines of its input
- `sort` sorts its input(s)
- `wc` counts lines, words and characters in its inputs
- `*` matches zero or more characters in a filename
- `?` matches any single character in a filename
- `command` `>` `file` redirects a command's output to a file
- `first` `|` `second` is a pipeline: the output of the first command is used as the input of the second
- the best way to use the shell is to use pipes to combine simple single-purpose programs (filters.)

* Finding things

* 

In the same way that many of use now use "Google" as a verb meaning "to find", UNIX programmers often use the word "grep".

`grep` is a contraction of "global/regular expression/print", a common sequence of operations in early UNIX text editors.
It is also the name of a very useful command-line program.

`grep` finds and prints lines in files that match a pattern.

* 

For our examples, we will use a file that contains three haikus taken from a 1998 competition in Salon magazine. For this set of examples, we’re going to be working in the writing subdirectory:

 $> cd ~/Downloads/data-shell/writing
 $> cat haiku.txt
 The Tao that is seen
 Is not the true Tao, until
 You bring fresh toner.
 
 With searching comes loss
 and the presence of absence:
 "My Thesis" not found.
 
 Yesterday it worked
 Today it is not working
 Software is like that.

* 

Let's find lines that contain the word "not":

 $> grep not haiku.txt
 Is not the true Tao, until
 "My Thesis" not found
 Today it is not working

Here, `"not"` is the pattern we're searching for.
The `grep` command searches through the file, looking for matches to the specified pattern.

 $> grep The haiku.txt
 The Tao that is seen
 "My Thesis" not found.

To restrict matches to lines containing the word "The" on its own:

 $> grep -w The haiku.txt
 The Tao that is seen

* 

Another useful option is `-n` which humbers the lines that match:

 $> grep -n "it" haiku.txt
 5:With searching comes loss
 9:Yesterday it worked
 10:Today it is not working

We can also use the option `-v` to invert our search:

 $> grep -n -v "it" haiku.txt
 1:The Tao that is seen
 2:Is not the true Tao, until
 3:You bring fresh toner.
 4:
 6:and the presence of absence:
 7:"My Thesis" not found.
 8:
 11:Software is like that.

* 

While `grep` finds lines in files, the `find` command finds files themselves.
Still in the `writing` directory with the following structure:

 .
 ├── data
 │   ├── LittleWomen.txt
 │   ├── one.txt
 │   └── two.txt
 ├── haiku.txt
 ├── old
 ├── thesis
 │   └── empty-draft.md
 └── tools
     ├── format
     ├── old
     │   └── oldtool
     └── stats

* 

Let's run `find`:

 $> find .
 .
 ./haiku.txt
 ./data
 ./data/one.txt
 ./data/two.txt
 ./data/LittleWomen.txt
 ./old
 ./old/.gitkeep
 ./thesis
 ./thesis/empty-draft.md
 ./tools
 ./tools/format
 ./tools/stats
 ./tools/old
 ./tools/old/oldtool

* 

The first option in our list is `-type` `d`: things that are directories.

 $> find . -type d
 .
 ./data
 ./old
 ./thesis
 ./tools
 ./tools/old

Notice that the objects `find` finds are not listed in any particular order.

* 

If we change to `-type` `f`, we get a listing of all the files instead:

 $> find . -type f
 ./haiku.txt
 ./data/one.txt
 ./data/two.txt
 ./data/LittleWomen.txt
 ./old/.gitkeep
 ./thesis/empty-draft.md
 ./tools/format
 ./tools/stats
 ./tools/old/oldtool

* 

Now, let's try matching by name:

 $> find . -name *.txt
 ./haiku.txt

We expected it to find all the text files, but it only prints out `./haiku.txt`.
The problem is that the shell expands wildcard characters like `*` before commands run.
Since `*.txt` in the current directory expands to `haiku.txt`, the command we actually ran was:

 $> find . -name haiku.txt

To prevent this, we need to run instead:

 $> find . -name '*.txt'
 ./haiku.txt
 ./data/one.txt
 ./data/two.txt
 ./data/LittleWomen.txt

* 

As said earlier, the command line's power lies in combining tools.
We've seen how to do that with pipes; let's look at another technique.

As we just saw:

 $> find . -name '*.txt'

gives us a list of all text files in or below the current directory.
How can we combine that with `wc` `-l` to count the lines in all those files?

The simplest way is to put the `find` command inside `$()`:

 $> wc -l $(find . -name '*.txt')
     11 ./haiku.txt
     70 ./data/one.txt
    300 ./data/two.txt
  21022 ./data/LittleWomen.txt
  21403 total

* Summary

- `find` finds files with specific properties that match patterns
- `grep` selects lines in files that match patterns
- `--help` is a flag supported by many bash commands and programs that can be run from within bash, to display more information on how to use these commands or programs
- `man` `command-name` displays the manual page for a given command
- `$(command)` inserts a command's output in place

# * UNIX - Files and processes
# 
# In UNIX, everything is either a file or a process.
# 
# A *process* is an executing program, identified by a unique *PID* (process identifier.)
# 
# A *file* is a collection of data.
# Files are created by users via text editors, running compilers or downloading from the internet.
 

* Resources

.link https://en.wikibooks.org/wiki/A_Quick_Introduction_to_Unix
.link https://en.wikipedia.org/wiki/Unix
.link https://swcarpentry.github.io/shell-novice/
.link http://www.ee.surrey.ac.uk/Teaching/Unix
.link https://www.tutorialspoint.com/unix/unix-getting-started.htm

